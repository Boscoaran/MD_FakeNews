{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datos/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocesar(c):\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    remove = []\n",
    "    for i in range(len(c)):\n",
    "        s = str(c[i])\n",
    "        if not bool(s):\n",
    "            remove.append(df['id'])\n",
    "        else:\n",
    "            s = s.lower()\n",
    "            s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "            s = s.translate(str.maketrans('', '', string.digits))\n",
    "            s = s.split()\n",
    "            stop_words=set(stopwords.words('english'))\n",
    "            filtered_sentence = [w for w in s if not w in stop_words]\n",
    "            filtered_sentence = []\n",
    "            for w in s:\n",
    "                if w not in stop_words and len(w)>1 and w.isascii():\n",
    "                    w = wnl.lemmatize(w)\n",
    "                    w = ps.stem(w)\n",
    "                    if len(w)>1:\n",
    "                        filtered_sentence.append(w)\n",
    "            if not bool(filtered_sentence):\n",
    "                remove.append(i)\n",
    "            c[i] = filtered_sentence\n",
    "    return(c, remove)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3884/346490496.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c[i] = filtered_sentence\n"
     ]
    }
   ],
   "source": [
    "df['title'], r1 = preprocesar(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3884/346490496.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c[i] = filtered_sentence\n"
     ]
    }
   ],
   "source": [
    "df['text'], r2 = preprocesar(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r1+r2\n",
    "r = list(dict.fromkeys(r))\n",
    "df = df.drop(df.index[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos prep/test_p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text    id\n",
      "0     ['palo', 'alto', 'calif', 'year', 'scorn', 'po...     1\n",
      "1     ['russian', 'warship', 'readi', 'strike', 'ter...     2\n",
      "2     ['video', 'nodapl', 'nativ', 'american', 'lead...     3\n",
      "3     ['first', 'succeed', 'tri', 'differ', 'sport',...     4\n",
      "4     ['min', 'ago', 'view', 'comment', 'like', 'fir...     5\n",
      "...                                                 ...   ...\n",
      "5116  ['dysfunct', 'plagu', 'megac', 'none', 'may', ...  5117\n",
      "5117  ['washington', 'gov', 'john', 'kasich', 'ohio'...  5118\n",
      "5118  ['good', 'morn', 'want', 'get', 'california', ...  5119\n",
      "5119  ['previou', 'next', 'marin', 'deploy', 'russia...  5120\n",
      "5120  ['perhap', 'seen', 'new', 'tv', 'seri', 'whose...  5121\n",
      "\n",
      "[5121 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datos prep/test_p.csv')\n",
    "df = df.drop(columns=['title', 'id', 'author'])\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'insert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner√≠a de Datos/Proyecto/preproceso.ipynb Celda 8\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner%C3%ADa%20de%20Datos/Proyecto/preproceso.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m i\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner%C3%ADa%20de%20Datos/Proyecto/preproceso.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m df_tfidfvect:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner%C3%ADa%20de%20Datos/Proyecto/preproceso.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     df_tfidfvect[r]\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39m, l[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner%C3%ADa%20de%20Datos/Proyecto/preproceso.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     i\u001b[39m=\u001b[39mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/run/media/bosco/71F14D0054E62EDF/UPV/4/4.1/Miner%C3%ADa%20de%20Datos/Proyecto/preproceso.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(df_tfidfvect)\n",
      "File \u001b[0;32m/opt/anaconda/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'insert'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(df['text'])\n",
    "n=tfidf_wm.shape[0]+1\n",
    "l = [item for item in range(1, n+1)]\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray())\n",
    "i=1\n",
    "for r in df_tfidfvect:\n",
    "    df_tfidfvect[r].insert(0, l[i])\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "\n",
    "print(df_tfidfvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('datos prep/test_p.csv')\n",
    "df = df[:3000]\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(df['text'])\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray())\n",
    "n=tfidf_wm.shape[0]\n",
    "l = [item for item in range(1, n+1)]\n",
    "df_tfidfvect.insert(0, \"id\", l)\n",
    "arr = df_tfidfvect.values.tolist()\n",
    "with open('datos prep/test_tfidf100.csv', 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerows(arr)\n",
    "#arr.to_csv('datos prep/test_tfidf100.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
