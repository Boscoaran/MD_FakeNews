{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datos/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocesar(c):\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    remove = []\n",
    "    for i in range(len(c)):\n",
    "        s = str(c[i])\n",
    "        if not bool(s):\n",
    "            remove.append(df['id'])\n",
    "        else:\n",
    "            s = s.lower()\n",
    "            s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "            s = s.translate(str.maketrans('', '', string.digits))\n",
    "            s = s.split()\n",
    "            stop_words=set(stopwords.words('english'))\n",
    "            filtered_sentence = [w for w in s if not w in stop_words]\n",
    "            filtered_sentence = []\n",
    "            for w in s:\n",
    "                if w not in stop_words and len(w)>1 and w.isascii():\n",
    "                    w = wnl.lemmatize(w)\n",
    "                    w = ps.stem(w)\n",
    "                    if len(w)>1:\n",
    "                        filtered_sentence.append(w)\n",
    "            if not bool(filtered_sentence):\n",
    "                remove.append(i)\n",
    "            c[i] = filtered_sentence\n",
    "    return(c, remove)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1923/346490496.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c[i] = filtered_sentence\n"
     ]
    }
   ],
   "source": [
    "df['title'], r1 = preprocesar(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1923/346490496.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c[i] = filtered_sentence\n"
     ]
    }
   ],
   "source": [
    "df['text'], r2 = preprocesar(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r1+r2\n",
    "r = list(dict.fromkeys(r))\n",
    "df = df.drop(df.index[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datos prep/train_p.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datos prep/train_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bosco/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TD-IDF Vectorizer\n",
      "\n",
      "        aa  aaa  aab  aach  aadhar  aaf  aah  aaj  aakar  aakash  ...  \\\n",
      "id                                                                ...   \n",
      "20800  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "20801  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "20802  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "20803  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "20804  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "...    ...  ...  ...   ...     ...  ...  ...  ...    ...     ...  ...   \n",
      "25995  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "25996  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "25997  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "25998  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "25999  0.0  0.0  0.0   0.0     0.0  0.0  0.0  0.0    0.0     0.0  ...   \n",
      "\n",
      "       zwielichtig  zwill  zwingen  zwirner  zwischen  zwischenf  zydeco  \\\n",
      "id                                                                         \n",
      "20800          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "20801          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "20802          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "20803          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "20804          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "...            ...    ...      ...      ...       ...        ...     ...   \n",
      "25995          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "25996          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "25997          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "25998          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "25999          0.0    0.0      0.0      0.0       0.0        0.0     0.0   \n",
      "\n",
      "       zygot  zyuganov   zz  \n",
      "id                           \n",
      "20800    0.0       0.0  0.0  \n",
      "20801    0.0       0.0  0.0  \n",
      "20802    0.0       0.0  0.0  \n",
      "20803    0.0       0.0  0.0  \n",
      "20804    0.0       0.0  0.0  \n",
      "...      ...       ...  ...  \n",
      "25995    0.0       0.0  0.0  \n",
      "25996    0.0       0.0  0.0  \n",
      "25997    0.0       0.0  0.0  \n",
      "25998    0.0       0.0  0.0  \n",
      "25999    0.0       0.0  0.0  \n",
      "\n",
      "[5121 rows x 57926 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_wm = tfidfvectorizer.fit_transform(df['text'])\n",
    "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(), index=df['id'], columns = tfidf_tokens)\n",
    "\n",
    "print(\"\\nTD-IDF Vectorizer\\n\")\n",
    "print(df_tfidfvect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8177e54e2642460115b7fac856e55878a27f2d5462fcf040b568be5f735ea7f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
